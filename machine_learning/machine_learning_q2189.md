#


## Item ID
2189

## Claim

4

## Claim Behavior (evidence)

[Parameters for tree booster](https://xgboost.readthedocs.io/en/latest/parameter.html#parameters-for-tree-booster)

[XGBoost: A Scalable Tree Boosting System](https://arxiv.org/pdf/1603.02754.pdf)

## Content Target

Machine Learning Models

## Cognitive Model

Comprehend

## Item Type

Multiple Choice

## Stem

When using a gradient boosted decision tree such as xgboost, which of the following hyperparameters should be _increased_ in order to reduce overfitting?

## Code Snippet (optional)


## Answer Key

L2 regularization term λ

## Distractors
### 1.

Learning rate η

### 2.

Maximum tree depth

### 3.

Subsample ratio


## Common errors, misconceptions, or irrelevant information:

D1, D2, and D3 should are all hyperparameters that should be *decreased* to reduce overfitting.



# Triplebyte Review


## Language Review: (TB only)


## Bias and Fairness Review: (TB only)


## Content Review: (TB only)

