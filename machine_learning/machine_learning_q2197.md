#


## Item ID
2197

## Claim

1

## Claim Behavior (evidence)

> Number of components (<= min(n_classes - 1, n_features)) for dimensionality reduction. 

-- [Linear Discriminant Analysis, scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis)



## Content Target

Data Manipulation

## Cognitive Model

Comprehend

## Item Type

Multiple Choice

## Stem

Linear discriminant analysis (LDA) is a common method for dimensionality reduction. 

Consider a dataset with 100 continuous input features and 3 target classes. After applying LDA, what is the possible number of output dimensions?

## Code Snippet (optional)

## Answer Key

Between 1 and 3, inclusive

## Distractors
### 1.

Between 1 and 2, inclusive

### 2.

Between 1 and 100, inclusive

### 3.

Between 1 and 99, inclusive


## Common errors, misconceptions, or irrelevant information:




# Triplebyte Review


## Language Review: (TB only)


## Bias and Fairness Review: (TB only)


## Content Review: (TB only)

